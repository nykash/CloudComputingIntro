{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nikash Das Cloud AI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V41C1oib1AL",
        "outputId": "9c221b2e-c93a-40a0-9e65-13dced2e8592"
      },
      "source": [
        "pip install azureml-sdk[notebooks] azureml-opendatasets matplotlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting azureml-sdk[notebooks]\n",
            "  Using cached https://files.pythonhosted.org/packages/e7/78/2158f78295b38c10e13c47eacd1a135b859614454b78af484d2b59b35f55/azureml_sdk-1.24.0-py3-none-any.whl\n",
            "Collecting azureml-opendatasets\n",
            "  Using cached https://files.pythonhosted.org/packages/84/40/96c29052bd598704028edb96dc2c1f0d991fce8f25d774e0aea933492504/azureml_opendatasets-1.24.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Collecting azureml-pipeline~=1.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/49/8c1b323eaf83e7e63f21238632e8cd21b742d45917d99a2ca67d19d53aed/azureml_pipeline-1.24.0-py3-none-any.whl\n",
            "Collecting azureml-train-automl-client~=1.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/7d/6c7fccf8b19393868c3c7c6ba1d8587aeaf0f8c41f8bb8cd3bdfda10a2af/azureml_train_automl_client-1.24.0-py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 5.8MB/s \n",
            "\u001b[?25hCollecting azureml-core~=1.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/5a/7c7972ee9186c344611bc3acc1a0618438cebac2a85e4420400edd88d710/azureml_core-1.24.0.post2-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 5.9MB/s \n",
            "\u001b[?25hCollecting azureml-dataset-runtime[fuse]~=1.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/20/b9/302b0cd2f4ec34c4ad9af4bc623a6ed433ad731ced5e3cf4e1e5e3c2bb51/azureml_dataset_runtime-1.24.0-py3-none-any.whl\n",
            "Collecting azureml-train~=1.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/0e/0a26ea8896156c244e7696bb6c058d3b360009c951148d87f5d178f671ad/azureml_train-1.24.0-py3-none-any.whl\n",
            "Collecting azureml-widgets~=1.24.0; extra == \"notebooks\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/b2/e35b65c3731c2414247ad0f1711612769beec5c0ce2dce2350ef494f03ad/azureml_widgets-1.24.0-py3-none-any.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 311kB/s \n",
            "\u001b[?25hCollecting azureml-contrib-notebook~=1.24.0; extra == \"notebooks\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/00/6892d59fc3a2c1624d66cb8e91d785baa6b8cf92755c8f09858108e473b9/azureml_contrib_notebook-1.24.0-py3-none-any.whl\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 61kB/s \n",
            "\u001b[?25hCollecting pandas<=1.0.0,>=0.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/cf/5d4614610a6be006ea5715f76e261cb8bc0031a97e43f9915bddb404a3f5/pandas-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (3.0.0)\n",
            "Requirement already satisfied: scipy<=1.4.1,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-opendatasets) (1.4.1)\n",
            "Collecting numpy<=1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/31/e2c3eda7afe7dab08e1f24767b8e38ff2f30dc82bd74aa3a5324c550366a/numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6MB 327kB/s \n",
            "\u001b[?25hCollecting azureml-telemetry~=1.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/f9/03365d9ee38a76ea47f0d7096417ed4827d99a027b4d3e12d6d51b70a83a/azureml_telemetry-1.24.0-py3-none-any.whl\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Collecting azureml-pipeline-steps~=1.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/62/d32bd91f7b491c744fa3804c87f0df5b4de7d1e7e63ef1c6c4fc7ab154fe/azureml_pipeline_steps-1.24.0-py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hCollecting azureml-pipeline-core~=1.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/88/90ecddfa7633f2007088dfa70d34730227b8febd22ba51aea4620b093ac7/azureml_pipeline_core-1.24.0-py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 38.8MB/s \n",
            "\u001b[?25hCollecting azureml-automl-core~=1.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/d2/5c9c08bf761f70cbf983a7e0c25b954063c03e20d14ab4339ee231b349c6/azureml_automl_core-1.24.0-py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.1MB/s \n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/1a/f2db026d4d682303793559f1c2bb425ba3ec0d6fd7ac63397790443f2461/jsonpickle-2.0.0-py2.py3-none-any.whl\n",
            "Collecting adal>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/a1/5f5fb9f4edb6e8b7882281158edc1cd465249c53fd48b1bf6af2c9237fe5/adal-1.2.6-py2.py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.5MB/s \n",
            "\u001b[?25hCollecting msrest>=0.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cc/6c96bfb3d3cf4c3bdedfa6b46503223f4c2a4fa388377697e0f8082a4fed/msrest-0.6.21-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.7MB/s \n",
            "\u001b[?25hCollecting backports.tempfile\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/70/8c2d0509db466678eba16fa2b0a539499f3b351b1f2993126ad843d5be13/azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 27.4MB/s \n",
            "\u001b[?25hCollecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/af/1ba15e7176bcf6b1531b453e410ae41a983c09f834d8700dfce739451b53/azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.4MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/9b/8850f99027ed029af6828199cc87179eaccbbf1f9e6e373e7f0177d32dad/PyJWT-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.24.0->azureml-sdk[notebooks]) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.24.0->azureml-sdk[notebooks]) (2018.9)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.24.0->azureml-sdk[notebooks]) (0.5.5)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.0MB/s \n",
            "\u001b[?25hCollecting pyopenssl<21.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5e/06351ede29fd4899782ad335c2e02f1f862a887c20a3541f17c3fa1a3525/pyOpenSSL-20.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.6MB/s \n",
            "\u001b[?25hCollecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/93/02056aca45162f9fc275d1eaad12a2a07ef92375afb48eabddc4134b8315/azure_graphrbac-0.61.1-py2.py3-none-any.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 48.0MB/s \n",
            "\u001b[?25hCollecting jmespath\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting msrestazure>=0.4.33\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/3a/7adb08fd2f0ee6fdfd03685fac38477b64f184943dcf6ea0cbffb205f22d/msrestazure-0.6.4-py2.py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 3.4MB/s \n",
            "\u001b[?25hCollecting pathspec\n",
            "  Downloading https://files.pythonhosted.org/packages/29/29/a465741a3d97ea3c17d21eaad4c64205428bde56742360876c4391f930d4/pathspec-0.8.1-py2.py3-none-any.whl\n",
            "Collecting docker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/22/410313ad554477e87ec406d38d85f810e61ddb0d2fc44e64994857476de9/docker-4.4.4-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 44.6MB/s \n",
            "\u001b[?25hCollecting azure-common>=1.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/19/2b/46ada1753c4a640bc3ad04a1e20b1a5ea52a8f18079e1b8238e536aa0c98/azure_common-1.1.26-py2.py3-none-any.whl\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/cc/8ace313fd151af6663b1e1778f216532eab0258133ef21498c0e2caefad6/azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.24.0->azureml-sdk[notebooks]) (1.24.3)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orr07w8Qbuik"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# check core SDK version number\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COAr7qTgdrak"
      },
      "source": [
        " import os\n",
        "    \n",
        " subscription_id = os.getenv(\"Azure For Students\", default=\"<Azure for Students>\")\n",
        " resource_group = os.getenv(\"TestResourceGroup\", default=\"<TestResourceGroup>\")\n",
        " workspace_name = os.getenv(\"TestWorkspace\", default=\"<TestWorkspace>\")\n",
        " workspace_region = os.getenv(\"eastus2\", default=\"eastus2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H674hQJldqA4"
      },
      "source": [
        " from azureml.core import Workspace\n",
        "    \n",
        " try:\n",
        "     ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
        "     # write the details of the workspace to a configuration file to the notebook library\n",
        "     ws.write_config()\n",
        "     print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
        " except:\n",
        "     print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clEqEVWwbxfz"
      },
      "source": [
        "#ws = Workspace.create(name=\"workspace1\",\n",
        "   #            subscription_id='dadde106-8e06-4182-9ece-f8238f8af613',\n",
        "  #             resource_group=\"resource1\", \n",
        "  #             create_resource_group = True,\n",
        "  ##             location='eastus2')\n",
        "print(ws.name, ws.location, ws.resource_group, sep='\\t')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FULld8PuiDHq"
      },
      "source": [
        " ws = Workspace.get(name=\"workspace1\",\n",
        "               subscription_id='dadde106-8e06-4182-9ece-f8238f8af613',\n",
        "               resource_group=\"resource1\", \n",
        "               )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQMVj80XfkFG"
      },
      "source": [
        "from azureml.core import Experiment\n",
        "experiment_name = 'Tutorial-sklearn-mnist'\n",
        "\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW2R-yxsiYWK"
      },
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "import os\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                                min_nodes=compute_min_nodes,\n",
        "                                                                max_nodes=compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(\n",
        "        ws, compute_name, provisioning_config)\n",
        "\n",
        "    # can poll for a minimum number of nodes and for a specific timeout.\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(\n",
        "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "\n",
        "    # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18KV-GTQjme4"
      },
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.opendatasets import MNIST\n",
        "\n",
        "data_folder = os.path.join(os.getcwd(), 'data')\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "mnist_file_dataset = MNIST.get_file_dataset()\n",
        "mnist_file_dataset.download(data_folder, overwrite=True)\n",
        "\n",
        "mnist_file_dataset = mnist_file_dataset.register(workspace=ws,\n",
        "                                                 name='mnist_opendataset',\n",
        "                                                 description='training and test dataset',\n",
        "                                                 create_new_version=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tYmUFLzjrj1"
      },
      "source": [
        "# make sure utils.py is in the same directory as this code\n",
        "from utils import load_data\n",
        "import glob\n",
        "\n",
        "\n",
        "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the model converge faster.\n",
        "X_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
        "X_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
        "y_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n",
        "y_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n",
        "\n",
        "\n",
        "# now let's show some randomly chosen images from the traininng set.\n",
        "count = 0\n",
        "sample_size = 30\n",
        "plt.figure(figsize=(16, 6))\n",
        "for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
        "    count = count + 1\n",
        "    plt.subplot(1, sample_size, count)\n",
        "    plt.axhline('')\n",
        "    plt.axvline('')\n",
        "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
        "    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJewokLDlHUh"
      },
      "source": [
        "import os\n",
        "script_folder = os.path.join(os.getcwd(), \"sklearn-mnist\")\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVt_6zlAlLE3"
      },
      "source": [
        "%%writefile $script_folder/train.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "from azureml.core import Run\n",
        "from utils import load_data\n",
        "\n",
        "# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
        "parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regularization rate')\n",
        "args = parser.parse_args()\n",
        "\n",
        "data_folder = args.data_folder\n",
        "print('Data folder:', data_folder)\n",
        "\n",
        "# load train and test set into numpy arrays\n",
        "# note we scale the pixel intensity values to 0-1 (by dividing it with 255.0) so the model can converge faster.\n",
        "X_train = load_data(glob.glob(os.path.join(data_folder, '**/train-images-idx3-ubyte.gz'), recursive=True)[0], False) / 255.0\n",
        "X_test = load_data(glob.glob(os.path.join(data_folder, '**/t10k-images-idx3-ubyte.gz'), recursive=True)[0], False) / 255.0\n",
        "y_train = load_data(glob.glob(os.path.join(data_folder, '**/train-labels-idx1-ubyte.gz'), recursive=True)[0], True).reshape(-1)\n",
        "y_test = load_data(glob.glob(os.path.join(data_folder, '**/t10k-labels-idx1-ubyte.gz'), recursive=True)[0], True).reshape(-1)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep = '\\n')\n",
        "\n",
        "# get hold of the current run\n",
        "run = Run.get_context()\n",
        "\n",
        "print('Train a logistic regression model with regularization rate of', args.reg)\n",
        "clf = LogisticRegression(C=1.0/args.reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print('Predict the test set')\n",
        "y_hat = clf.predict(X_test)\n",
        "\n",
        "# calculate accuracy on the prediction\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy is', acc)\n",
        "\n",
        "run.log('regularization rate', np.float(args.reg))\n",
        "run.log('accuracy', np.float(acc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=clf, filename='outputs/sklearn_mnist_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_9jKfc7lMh6"
      },
      "source": [
        "import shutil\n",
        "shutil.copy('utils.py', script_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JWiYuWDlT_T"
      },
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# to install required packages\n",
        "env = Environment('tutorial-env')\n",
        "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages=['scikit-learn==0.22.1'])\n",
        "\n",
        "env.python.conda_dependencies = cd\n",
        "\n",
        "# Register environment to re-use later\n",
        "env.register(workspace=ws)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neCWRNeol5SI"
      },
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "args = ['--data-folder', mnist_file_dataset.as_mount(), '--regularization', 0.5]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script='train.py', \n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u8pni9flgW1"
      },
      "source": [
        "run = exp.submit(config=src)\n",
        "run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEFTTCYOmJEc"
      },
      "source": [
        "from azureml.widgets import RunDetails\n",
        "run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOrnn952NipW"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import azureml.core\n",
        "\n",
        "# Display the core SDK version number\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEYvMkW7NnBo"
      },
      "source": [
        "%%writefile score.py\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_mnist_model.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "def run(raw_data):\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # make prediction\n",
        "    y_hat = model.predict(data)\n",
        "    # you can return any data type as long as it is JSON-serializable\n",
        "    return y_hat.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE67-UtiNpe8"
      },
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={\"data\": \"MNIST\",  \"method\" : \"sklearn\"}, \n",
        "                                               description='Predict MNIST with sklearn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MYwTKj5Nr6Y"
      },
      "source": [
        "%%time\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.model import Model\n",
        "\n",
        "model = Model(ws, 'sklearn_mnist')\n",
        "\n",
        "\n",
        "myenv = Environment.get(workspace=ws, name=\"tutorial-env\", version=\"1\")\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
        "\n",
        "service = Model.deploy(workspace=ws, \n",
        "                       name='sklearn-mnist-svc3', \n",
        "                       models=[model], \n",
        "                       inference_config=inference_config, \n",
        "                       deployment_config=aciconfig)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(service.scoring_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9PzJRVHNwTp"
      },
      "source": [
        "import os\n",
        "from azureml.core import Dataset\n",
        "from azureml.opendatasets import MNIST\n",
        "\n",
        "data_folder = os.path.join(os.getcwd(), 'data')\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "mnist_file_dataset = MNIST.get_file_dataset()\n",
        "mnist_file_dataset.download(data_folder, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R4nYuDINzlf"
      },
      "source": [
        "from utils import load_data\n",
        "import os\n",
        "import glob\n",
        "\n",
        "data_folder = os.path.join(os.getcwd(), 'data')\n",
        "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the neural network converge faster\n",
        "X_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
        "y_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K4ArmE0N1IL"
      },
      "source": [
        "import json\n",
        "test = json.dumps({\"data\": X_test.tolist()})\n",
        "test = bytes(test, encoding='utf8')\n",
        "y_hat = service.run(input_data=test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOokBmgoN2d9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_mx = confusion_matrix(y_test, y_hat)\n",
        "print(conf_mx)\n",
        "print('Overall accuracy:', np.average(y_hat == y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0JqlaxNN3oe"
      },
      "source": [
        "# normalize the diagonal cells so that they don't overpower the rest of the cells when visualized\n",
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums\n",
        "np.fill_diagonal(norm_conf_mx, 0)\n",
        "\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(norm_conf_mx, cmap=plt.cm.bone)\n",
        "ticks = np.arange(0, 10, 1)\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(ticks)\n",
        "ax.set_yticklabels(ticks)\n",
        "fig.colorbar(cax)\n",
        "plt.ylabel('true labels', fontsize=14)\n",
        "plt.xlabel('predicted values', fontsize=14)\n",
        "plt.savefig('conf.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msbSHcYIN5dZ"
      },
      "source": [
        "import json\n",
        "\n",
        "# find 30 random samples from test set\n",
        "n = 30\n",
        "sample_indices = np.random.permutation(X_test.shape[0])[0:n]\n",
        "\n",
        "test_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\n",
        "test_samples = bytes(test_samples, encoding='utf8')\n",
        "\n",
        "# predict using the deployed model\n",
        "result = service.run(input_data=test_samples)\n",
        "\n",
        "# compare actual value vs. the predicted values:\n",
        "i = 0\n",
        "plt.figure(figsize = (20, 1))\n",
        "\n",
        "for s in sample_indices:\n",
        "    plt.subplot(1, n, i + 1)\n",
        "    plt.axhline('')\n",
        "    plt.axvline('')\n",
        "    \n",
        "    # use different color for misclassified sample\n",
        "    font_color = 'red' if y_test[s] != result[i] else 'black'\n",
        "    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n",
        "    \n",
        "    plt.text(x=10, y=-10, s=result[i], fontsize=18, color=font_color)\n",
        "    plt.imshow(X_test[s].reshape(28, 28), cmap=clr_map)\n",
        "    \n",
        "    i = i + 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}